{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Flower Predictions ~ Classification model\n",
    "Here we are going to consider the properties of the flower and classify them into their particular classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "\n",
    "from __future__ import absolute_import, division , print_function ,unicode_literals\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "This dataset seperates flowers into three different classes of species.\n",
    " - Setosa\n",
    " - Versicolor\n",
    " - Virginica\n",
    "\n",
    "The information of each flower is the following:\n",
    "- Sepal length\n",
    "- Sepal width\n",
    "- Petal Length\n",
    "- Petal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names\n",
    "CSV_COLUMN_NAMES = ['SepalLength' , 'SepalWidth' , 'PetalLength' , 'PetalWidth' , 'Species']\n",
    "SPECIES = ['Setosa' , 'Versicolor' , 'Virginica' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = tf.keras.utils.get_file('iris_training.csv' , 'https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv')\n",
    "test_path = tf.keras.utils.get_file('iris_test.csv' ,'https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv')\n",
    "\n",
    "train = pd.read_csv(train_path , names = CSV_COLUMN_NAMES, header = 0)\n",
    "test = pd.read_csv(test_path , names = CSV_COLUMN_NAMES , header = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lets check our dataset\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          5.9         3.0          4.2         1.5        1\n",
       "1          6.9         3.1          5.4         2.1        2\n",
       "2          5.1         3.3          1.7         0.5        0\n",
       "3          6.0         3.4          4.5         1.6        1\n",
       "4          5.5         2.5          4.0         1.3        1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    1\n",
       "2    2\n",
       "3    0\n",
       "4    0\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets separate y from the dataset\n",
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating input function\n",
    "\n",
    "def input_fn(features , labels , training = True , batch_size = 256):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features) , labels))\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Local\\Temp\\ipykernel_26804\\1562250211.py:4: numeric_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# Creating feature columns\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key = key))\n",
    "print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "And now  we are ready to choose a model. For classification tasks there are variety of different estimatios/ models that we can pick from. Some options are listed below:\n",
    " - DNNClassifies (Deep Neural Network)\n",
    " - LinearClassifier\n",
    "\n",
    "We can choose either model but the DNN seems to be the best choice. This is because we may not be able to find the linear correspondence in our data.\n",
    "So lets build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py:74: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Local\\Temp\\ipykernel_26804\\3183006745.py:2: DNNClassifierV2.__init__ (from tensorflow_estimator.python.estimator.canned.dnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\head_utils.py:59: MultiClassHead.__init__ (from tensorflow_estimator.python.estimator.head.multi_class_head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\base_head.py:696: The name tf.debugging.assert_greater is deprecated. Please use tf.compat.v1.debugging.assert_greater instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py:759: Estimator.__init__ (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1844: RunConfig.__init__ (from tensorflow_estimator.python.estimator.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1845: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\run_config.py:329: The name tf.GraphOptions is deprecated. Please use tf.compat.v1.GraphOptions instead.\n",
      "\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ANIKET~1\\AppData\\Local\\Temp\\tmp5tkcemko\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ANIKET~1\\\\AppData\\\\Local\\\\Temp\\\\tmp5tkcemko', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build DNN with 2 hidden layers with 30 and 10 hidden nodes each/\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns= my_feature_columns,\n",
    "    hidden_units=[30,10],\n",
    "    n_classes=3 #since we have 3 classes of flower\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:385: StopAtStepHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1205: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py:58: The name tf.data.make_initializable_iterator is deprecated. Please use tf.compat.v1.data.make_initializable_iterator instead.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\version_utils.py:76: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\autograph\\converters\\directives.py:126: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\legacy\\adagrad.py:93: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\model_fn.py:250: EstimatorSpec.__new__ (from tensorflow_estimator.python.estimator.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1416: NanTensorHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1419: LoggingTensorHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py:232: SecondOrStepTimer.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1456: CheckpointSaverHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\training\\monitored_session.py:579: StepCounterHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\training\\monitored_session.py:586: SummarySaverHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\ANIKET~1\\AppData\\Local\\Temp\\tmp5tkcemko\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\training\\monitored_session.py:1455: SessionRunArgs.__new__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\training\\monitored_session.py:1454: SessionRunContext.__init__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\training\\monitored_session.py:1474: SessionRunValues.__new__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:loss = 2.3099222, step = 0\n",
      "INFO:tensorflow:global_step/sec: 423.658\n",
      "INFO:tensorflow:loss = 1.3947804, step = 100 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 730.9\n",
      "INFO:tensorflow:loss = 1.209434, step = 200 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.965\n",
      "INFO:tensorflow:loss = 1.110174, step = 300 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 636.865\n",
      "INFO:tensorflow:loss = 1.0692837, step = 400 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.838\n",
      "INFO:tensorflow:loss = 1.0234493, step = 500 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 801.601\n",
      "INFO:tensorflow:loss = 0.99651724, step = 600 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 694.211\n",
      "INFO:tensorflow:loss = 0.95798516, step = 700 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.82\n",
      "INFO:tensorflow:loss = 0.95399874, step = 800 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 656.255\n",
      "INFO:tensorflow:loss = 0.9221021, step = 900 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.453\n",
      "INFO:tensorflow:loss = 0.9022968, step = 1000 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 635.4\n",
      "INFO:tensorflow:loss = 0.8710273, step = 1100 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 698.274\n",
      "INFO:tensorflow:loss = 0.86329997, step = 1200 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 716.707\n",
      "INFO:tensorflow:loss = 0.84562445, step = 1300 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.035\n",
      "INFO:tensorflow:loss = 0.81829095, step = 1400 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.368\n",
      "INFO:tensorflow:loss = 0.80187434, step = 1500 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 914.932\n",
      "INFO:tensorflow:loss = 0.79999655, step = 1600 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 889.611\n",
      "INFO:tensorflow:loss = 0.7696488, step = 1700 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.413\n",
      "INFO:tensorflow:loss = 0.7527734, step = 1800 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 850.535\n",
      "INFO:tensorflow:loss = 0.73910534, step = 1900 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 843.831\n",
      "INFO:tensorflow:loss = 0.74359816, step = 2000 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 782.292\n",
      "INFO:tensorflow:loss = 0.722496, step = 2100 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.791\n",
      "INFO:tensorflow:loss = 0.716377, step = 2200 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 832.666\n",
      "INFO:tensorflow:loss = 0.69459724, step = 2300 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.234\n",
      "INFO:tensorflow:loss = 0.6864903, step = 2400 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.06\n",
      "INFO:tensorflow:loss = 0.6746961, step = 2500 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.662\n",
      "INFO:tensorflow:loss = 0.65647197, step = 2600 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.37\n",
      "INFO:tensorflow:loss = 0.64684117, step = 2700 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.765\n",
      "INFO:tensorflow:loss = 0.64589876, step = 2800 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.037\n",
      "INFO:tensorflow:loss = 0.6282662, step = 2900 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.654\n",
      "INFO:tensorflow:loss = 0.6192487, step = 3000 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 672.318\n",
      "INFO:tensorflow:loss = 0.60210484, step = 3100 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.114\n",
      "INFO:tensorflow:loss = 0.6090397, step = 3200 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 625.521\n",
      "INFO:tensorflow:loss = 0.59739625, step = 3300 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.638\n",
      "INFO:tensorflow:loss = 0.5900544, step = 3400 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.384\n",
      "INFO:tensorflow:loss = 0.5810971, step = 3500 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 831.637\n",
      "INFO:tensorflow:loss = 0.56697273, step = 3600 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 839.953\n",
      "INFO:tensorflow:loss = 0.5450674, step = 3700 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.524\n",
      "INFO:tensorflow:loss = 0.5315714, step = 3800 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 831.579\n",
      "INFO:tensorflow:loss = 0.5273339, step = 3900 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 831.125\n",
      "INFO:tensorflow:loss = 0.5055903, step = 4000 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 867.201\n",
      "INFO:tensorflow:loss = 0.5150337, step = 4100 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 861.961\n",
      "INFO:tensorflow:loss = 0.50149524, step = 4200 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 801.402\n",
      "INFO:tensorflow:loss = 0.5108124, step = 4300 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 832.281\n",
      "INFO:tensorflow:loss = 0.49522835, step = 4400 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 827.553\n",
      "INFO:tensorflow:loss = 0.4884959, step = 4500 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.264\n",
      "INFO:tensorflow:loss = 0.47751904, step = 4600 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.514\n",
      "INFO:tensorflow:loss = 0.47289598, step = 4700 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 746.324\n",
      "INFO:tensorflow:loss = 0.4809761, step = 4800 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 834.415\n",
      "INFO:tensorflow:loss = 0.47217256, step = 4900 (0.121 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\ANIKET~1\\AppData\\Local\\Temp\\tmp5tkcemko\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.46620014.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x1b579acfdd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model.\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train , train_y , training= True),\n",
    "    steps = 5000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1821: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
      "\n",
      "INFO:tensorflow:Starting evaluation at 2024-02-19T03:56:48\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\training\\evaluation.py:260: FinalOpsHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ANIKET~1\\AppData\\Local\\Temp\\tmp5tkcemko\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.30875s\n",
      "INFO:tensorflow:Finished evaluation at 2024-02-19-03:56:48\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.9, average_loss = 0.5432546, global_step = 5000, loss = 0.5432546\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\ANIKET~1\\AppData\\Local\\Temp\\tmp5tkcemko\\model.ckpt-5000\n",
      "\n",
      " Test set accuracy: 0.900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Model\n",
    "\n",
    "eval_result = classifier.evaluate(input_fn=lambda: input_fn(test , test_y , training= False))\n",
    "print('\\n Test set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type numeric values as prompted.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\base_head.py:786: ClassificationOutput.__init__ (from tensorflow.python.saved_model.model_utils.export_output) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Aniketh Rai\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\multi_class_head.py:455: PredictOutput.__init__ (from tensorflow.python.saved_model.model_utils.export_output) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ANIKET~1\\AppData\\Local\\Temp\\tmp5tkcemko\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Virginica\" (74.0%)\n"
     ]
    }
   ],
   "source": [
    "def input_fn(features , batch_size = 256):\n",
    "    #convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "features = ['SepalLength' , 'SepalWidth' , 'PetalLength' , 'PetalWidth' ]\n",
    "predict = {}\n",
    "\n",
    "print('Please type numeric values as prompted.')\n",
    "for feature in features:\n",
    "    valid = True\n",
    "    while valid:\n",
    "        val = input(feature + \": \")\n",
    "        if not val.isdigit(): valid = False\n",
    "    predict[feature] = [float(val)]\n",
    "\n",
    "predictions = classifier.predict(input_fn = lambda: input_fn(predict))\n",
    "for pred_dict in predictions:\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "    \n",
    "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
    "        SPECIES[class_id], 100 * probability\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ANIKET~1\\AppData\\Local\\Temp\\tmp5tkcemko\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Setosa\" (72.4%)\n",
      "Expected is Setosa\n",
      "Prediction is \"Versicolor\" (47.5%)\n",
      "Expected is Versicolor\n",
      "Prediction is \"Virginica\" (61.7%)\n",
      "Expected is Virginica\n"
     ]
    }
   ],
   "source": [
    "# Testing manually\n",
    "expected = ['Setosa' , 'Versicolor' , 'Virginica']\n",
    "predict_x  = {\n",
    "    'SepalLength' : [5.1 , 5.9 , 6.9],\n",
    "    \"SepalWidth\" : [3.3 , 3.0 , 3.1],\n",
    "    \"PetalLength\" : [1.7 , 4.2 , 5.4],\n",
    "    \"PetalWidth\" : [0.5 , 1.5 , 2.1] \n",
    "}\n",
    "predictions = classifier.predict(input_fn = lambda: input_fn(predict_x))\n",
    "for pred_dict in predictions:\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "    \n",
    "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
    "        SPECIES[class_id], 100 * probability\n",
    "    ))\n",
    "    print( f'Expected is {expected[class_id]}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
